FPR[i]=t[1,2]/sum(t[,2])
}
return (list(TPR=TPR,FPR=FPR))
}
list_result = ROC(test[,49], Prob_k5, p_seq)
plot(x=list_result$FPR, y=list_result$TPR, xlab="FPR", ylab="TPR", xlim=c(0,1), ylim=c(0,1))
# Returns a list with the vales for the ROC curve
ROC = function(Y, Yfit, p){
m=length(p)
TPR=numeric(m)
FPR=numeric(m)
for(i in 1:m){
Ypred=ifelse(Yfit>p[i],1,0)
t=table('pred'=Ypred, 'true'=Y)
print(t)
TPR[i]=t[1,1]/sum(t[,1])
FPR[i]=t[1,2]/sum(t[,2])
}
return (list(TPR=TPR,FPR=FPR))
}
list_result = ROC(test[,49], Prob_k5, p_seq)
plot(x=list_result$FPR, y=list_result$TPR, xlab="FPR", ylab="TPR", xlim=c(0,1), ylim=c(0,1))
install.package("kknn")
install.packages("kknn")
library(MASS)
# Task 1
dataframe = read.csv("tecator.csv", dec=',')
dataframe = dataframe[-215,]
protein = dataframe$Protein
moisture = dataframe$Moisture
fat = dataframe$Fat
channels = as.matrix(dataframe[1:100])
plot(protein, moisture)
# Task 2
# M1 = B0+B1*p+ε, where ε = N~(0, σ)
# M2 = B0+B1*p+B2*p²+ε, where ε=N~(0, σ)
# M3 = B0+B1*p+B2*p²+B3*p³+ε, where ε=N~(0, σ)
# etc.
# MSE criterion is appropriate to use since it minimizes the errors in our predicions (deviation of ε)
# Task 3
n = dim(dataframe)[1]
ids = sample(1:n, floor(n/2))
training = dataframe[ids,]
validation = dataframe[-ids,]
p = training$Protein
p2 = p^2
p3 = p^3
p4 = p^4
p5 = p^5
p6 = p^6
X1 = cbind(p)
X2 = cbind(p, p2)
X3 = cbind(p, p2, p3)
X4 = cbind(p, p2, p3, p4)
X5 = cbind(p, p2, p3, p4, p5)
X6 = cbind(p, p2, p3, p4, p5, p6)
#B = solve(t(X)%*%X)%*%t(X)%*%Y if I was to calculate it myself, did not work for higher polynomial terms of power
M1 = lm(Moisture ~ X1, data=training)
M2 = lm(Moisture ~ X2, data=training)
M3 = lm(Moisture ~ X3, data=training)
M4 = lm(Moisture ~ X4, data=training)
M5 = lm(Moisture ~ X5, data=training)
M6 = lm(Moisture ~ X6, data=training)
# Make the predictions
fitted_validation1 = predict(M1, validation)
fitted_validation2 = predict(M2, validation)
fitted_validation3 = predict(M3, validation)
fitted_validation4 = predict(M4, validation)
fitted_validation5 = predict(M5, validation)
fitted_validation6 = predict(M6, validation)
fitted_training1 = predict(M1)
fitted_training2 = predict(M2)
fitted_training3 = predict(M3)
fitted_training4 = predict(M4)
fitted_training5 = predict(M5)
fitted_training6 = predict(M6)
# Calculate the MSEs
# Validation MSEs
mse_v1 = mean((validation$Moisture-fitted_validation1)^2)
mse_v2 = mean((validation$Moisture-fitted_validation2)^2)
mse_v3 = mean((validation$Moisture-fitted_validation3)^2)
mse_v4 = mean((validation$Moisture-fitted_validation4)^2)
mse_v5 = mean((validation$Moisture-fitted_validation5)^2)
mse_v6 = mean((validation$Moisture-fitted_validation6)^2)
# Training MSEs
mse_t1 = mean((training$Moisture-fitted_training1)^2)
mse_t2 = mean((training$Moisture-fitted_training2)^2)
mse_t3 = mean((training$Moisture-fitted_training3)^2)
mse_t4 = mean((training$Moisture-fitted_training4)^2)
mse_t5 = mean((training$Moisture-fitted_training5)^2)
mse_t6 = mean((training$Moisture-fitted_training6)^2)
# Plot
mse_v = c(mse_v1, mse_v2, mse_v3, mse_v4, mse_v5, mse_v6)
mse_t = c(mse_t1, mse_t2, mse_t3, mse_t4, mse_t5, mse_t6)
plot(1:6, mse_v, type="l", col="green", ylim=c(0,160))
lines(1:6, mse_t, type="l", col="blue")
plot(1:6, mse_v, type="l", col="green", ylim=c(0,180))
lines(1:6, mse_t, type="l", col="blue")
fit = lm(Fat~., data=training)
step = stepAIC(fit, direction="both")
step$anova
summary(step)
plot(θ, log_bayesian_model, type="l", xlim=c(0,1), ylim=c(-500, 0), main="Bayesian model", xlab="θ", ylab="Log-Bayesian", col="green")
# returns the loglikelihood value for given θ and vector X
loglikelihood = function(x, θ){
return(length(x)*log(θ)-θ*sum(x))
}
# returns the max logilikelihood value for the given distribution estimation
max_loglikelihood = function(x){
return(length(x)/sum(x))
}
# returns log value of the bayesian proportional probability for given θ, λ and vector X
log_bayesian = function(x, θ, λ){
n = length(x)
return(n*log(θ)-θ*sum(x)+n*log(λ)-n*λ*θ)
}
max_bayesian = function(x, λ){
n = length(x)
return (n/(sum(x)+n*λ))
}
###########################################################################
# Task 1
# Data preparation
dataframe = read.csv("machines.csv", dec=',')
X = dataframe[1]$Length # X vector
X_6 = X[1:6] # X vector of first 6 values
θ = seq(from=0, to=20, by=0.025) # θs to test
m = length(θ) # Amount of θs to be tested
loglikelihood_n = numeric(m) # Empty vector for loglikelihood values with all x values
loglikelihood_6 = numeric(m) # Empty vector for loglikelihood values the first 6 values
# Task 2
# Calculate the loglikelihoods for different θ values with the given vectors
for(i in 1:m){
loglikelihood_n[i] = loglikelihood(X, θ[i])
loglikelihood_6[i] = loglikelihood(X_6, θ[i])
}
# Task 3
# Plot the loglikelihoods
plot(θ, loglikelihood_6, type="l", main="Dependence of Log-Likelihood and θ (n values)", xlab="θ", ylab="Log-Likelihood", col="green")
lines(θ, loglikelihood_n, col="blue")
# θ values for maximum loglikelihoods
θstar_n = max_loglikelihood(X)
θstar_6 = max_loglikelihood(X_6)
# Task 4
# Plot the Bayesian Model
λ = 10;
log_bayesian_model = numeric(m)
for(i in 1:m){
log_bayesian_model[i] = log_bayesian(X, θ[i], λ)
}
plot(θ, log_bayesian_model, type="l", xlim=c(0,1), ylim=c(-500, 0), main="Bayesian model", xlab="θ", ylab="Log-Bayesian", col="green")
θstar_b = max_bayesian(X, λ)
plot(θ, log_bayesian_model, type="l", xlim=c(0,1), ylim=c(-500, 0), main="Bayesian model", xlab="θ", ylab="Log-Bayesian", col="green")
new_observations = rexp(n=50, rate = θstar_n)
data.frame(X, new_observations)
hist(new_observations, col="green", xlim=c(0,5), ylim=c(0,25), main="Original observations", xlab="x")
x11()
hist(X, col="blue", xlim=c(0,5), ylim=c(0,25), main="New observations", xlab="x")
fit = lm(Fat~., data=training)
step = stepAIC(fit, direction="both")
step$anova
summary(step)
help(stepAIC)
library(MASS)
# Task 1
dataframe = read.csv("tecator.csv", dec=',')
dataframe = dataframe[-215,]
protein = dataframe$Protein
moisture = dataframe$Moisture
fat = dataframe$Fat
channels = as.matrix(dataframe[1:100])
plot(protein, moisture)
# Task 2
# M1 = B0+B1*p+ε, where ε = N~(0, σ)
# M2 = B0+B1*p+B2*p²+ε, where ε=N~(0, σ)
# M3 = B0+B1*p+B2*p²+B3*p³+ε, where ε=N~(0, σ)
# etc.
# MSE criterion is appropriate to use since it minimizes the errors in our predicions (deviation of ε)
# Task 3
n = dim(dataframe)[1]
ids = sample(1:n, floor(n/2))
training = dataframe[ids,]
validation = dataframe[-ids,]
p = training$Protein
p2 = p^2
p3 = p^3
p4 = p^4
p5 = p^5
p6 = p^6
X1 = cbind(p)
X2 = cbind(p, p2)
X3 = cbind(p, p2, p3)
X4 = cbind(p, p2, p3, p4)
X5 = cbind(p, p2, p3, p4, p5)
X6 = cbind(p, p2, p3, p4, p5, p6)
#B = solve(t(X)%*%X)%*%t(X)%*%Y if I was to calculate it myself, did not work for higher polynomial terms of power
M1 = lm(Moisture ~ X1, data=training)
M2 = lm(Moisture ~ X2, data=training)
M3 = lm(Moisture ~ X3, data=training)
M4 = lm(Moisture ~ X4, data=training)
M5 = lm(Moisture ~ X5, data=training)
M6 = lm(Moisture ~ X6, data=training)
# Make the predictions
fitted_validation1 = predict(M1, validation)
fitted_validation2 = predict(M2, validation)
fitted_validation3 = predict(M3, validation)
fitted_validation4 = predict(M4, validation)
fitted_validation5 = predict(M5, validation)
fitted_validation6 = predict(M6, validation)
fitted_training1 = predict(M1)
fitted_training2 = predict(M2)
fitted_training3 = predict(M3)
fitted_training4 = predict(M4)
fitted_training5 = predict(M5)
fitted_training6 = predict(M6)
# Calculate the MSEs
# Validation MSEs
mse_v1 = mean((validation$Moisture-fitted_validation1)^2)
mse_v2 = mean((validation$Moisture-fitted_validation2)^2)
mse_v3 = mean((validation$Moisture-fitted_validation3)^2)
mse_v4 = mean((validation$Moisture-fitted_validation4)^2)
mse_v5 = mean((validation$Moisture-fitted_validation5)^2)
mse_v6 = mean((validation$Moisture-fitted_validation6)^2)
# Training MSEs
mse_t1 = mean((training$Moisture-fitted_training1)^2)
mse_t2 = mean((training$Moisture-fitted_training2)^2)
mse_t3 = mean((training$Moisture-fitted_training3)^2)
mse_t4 = mean((training$Moisture-fitted_training4)^2)
mse_t5 = mean((training$Moisture-fitted_training5)^2)
mse_t6 = mean((training$Moisture-fitted_training6)^2)
# Plot
mse_v = c(mse_v1, mse_v2, mse_v3, mse_v4, mse_v5, mse_v6)
mse_t = c(mse_t1, mse_t2, mse_t3, mse_t4, mse_t5, mse_t6)
plot(1:6, mse_v, type="l", col="green", ylim=c(0,180))
lines(1:6, mse_t, type="l", col="blue")
#Task 4
fit = lm(Fat~., data=training)
step = stepAIC(fit, direction="both")
step$anova
summary(step)
step
step$coefficients
step$anova
colnames(training)
fit = lm(Fat~colnames(training)[c("Moisture", "Protein", "Sample")], data=training)
colnames(training)[c("Moisture", "Protein", "Sample")]
fit = lm(Fat~colnames(training)[-c("Moisture", "Protein", "Sample")], data=training)
colnames(training)[c("Moisture", "Protein", "Sample")]
colnames(training)[-c("Moisture", "Protein", "Sample")]
fit = lm(Fat~colnames(training[-c("Moisture", "Protein", "Sample")])[,], data=training)
fit = lm(Fat~colnames(training[,-c("Moisture", "Protein", "Sample")])[,], data=training)
fit = lm(Fat~colnames(training[,-c("Moisture", "Protein", "Sample")]), data=training)
colnames(training[,-c("Moisture", "Protein", "Sample")])
colnames(training[-c("Moisture", "Protein", "Sample")])
colnames(training[,-c("Moisture")])
colnames(training[,-"Moisture"])
training[,colnames(training]
colnames(training)
colnames(training) %in% c("Sample", "Fat", "Protein", "Moisture")
idx = !colnames(training) %in% c("Sample", "Fat", "Protein", "Moisture")
colnames(training[,idx])
paste(colnames(training[,idx]), collapse = "+")
fit = lm(formula(Fat~paste(colnames(training[,idx]), collapse = "+")), data=training)
fit = lm(formula=(Fat~paste(colnames(training[,idx]), collapse = "+")), data=training)
formula(Fat~paste(colnames(training[,idx]), collapse = "+"))
formulax = (Fat~paste(colnames(training[,idx]), collapse = "+"))
formulax = (Fat~paste(colnames(training[,idx]), collapse = "+"))
formulax
formulax = Fat~paste(colnames(training[,idx]), collapse = "+")
fit = lm(formula(formulax), data=training)
formulax
formulax = paste("Fat~", paste(colnames(training[,idx]), collapse = "+"))
formulax
fit = lm(formula(formulax), data=training)
step = stepAIC(fit, direction="both")
step$anova
idx = !colnames(training) %in% c("Sample", "Fat", "Protein", "Moisture")
formulax = paste("Fat~", paste(colnames(training[,idx]), collapse = "+"))
fit = lm(formula(formulax), data=training)
step = stepAIC(fit, direction="both")
step$anova
summary(step)
coef(step)
training = dataframe[ids,]
fit = lm(formula(formulax), data=dataframe)
step = stepAIC(fit, direction="both")
idx = !colnames(training) %in% c("Sample", "Fat", "Protein", "Moisture")
formulax = paste("Fat~", paste(colnames(training[,idx]), collapse = "+"))
fit = lm(formula(formulax), data=dataframe)
step = stepAIC(fit, direction="both")
step$anova
summary(step)
log_bayesian = function(x, θ, λ){
n = length(x)
#return(n*log(θ)-θ*sum(x)+n*log(λ)-n*λ*θ)
return(n*log(θ)-θ*sum(x)+log(λ)-λ*θ)
}
λ = 10;
log_bayesian_model = numeric(m)
for(i in 1:m){
log_bayesian_model[i] = log_bayesian(X, θ[i], λ)
}
plot(θ, log_bayesian_model, type="l", xlim=c(0,1), ylim=c(-500, 0), main="Bayesian model", xlab="θ", ylab="Log-Bayesian", col="green")
# returns the loglikelihood value for given θ and vector X
loglikelihood = function(x, θ){
return(length(x)*log(θ)-θ*sum(x))
}
# returns the max logilikelihood value for the given distribution estimation
max_loglikelihood = function(x){
return(length(x)/sum(x))
}
# returns log value of the bayesian proportional probability for given θ, λ and vector X
log_bayesian = function(x, θ, λ){
n = length(x)
#return(n*log(θ)-θ*sum(x)+n*log(λ)-n*λ*θ)
return(n*log(θ)-θ*sum(x)+log(λ)-λ*θ)
}
max_bayesian = function(x, λ){
n = length(x)
return (n/(sum(x)+n*λ))
}
###########################################################################
# Task 1
# Data preparation
dataframe = read.csv("machines.csv", dec=',')
X = dataframe[1]$Length # X vector
X_6 = X[1:6] # X vector of first 6 values
θ = seq(from=0, to=20, by=0.025) # θs to test
m = length(θ) # Amount of θs to be tested
loglikelihood_n = numeric(m) # Empty vector for loglikelihood values with all x values
loglikelihood_6 = numeric(m) # Empty vector for loglikelihood values the first 6 values
# Task 2
# Calculate the loglikelihoods for different θ values with the given vectors
for(i in 1:m){
loglikelihood_n[i] = loglikelihood(X, θ[i])
loglikelihood_6[i] = loglikelihood(X_6, θ[i])
}
# Task 3
# Plot the loglikelihoods
plot(θ, loglikelihood_6, type="l", main="Dependence of Log-Likelihood and θ (n values)", xlab="θ", ylab="Log-Likelihood", col="green")
lines(θ, loglikelihood_n, col="blue")
# θ values for maximum loglikelihoods
θstar_n = max_loglikelihood(X)
θstar_6 = max_loglikelihood(X_6)
# Task 4
# Plot the Bayesian Model
λ = 10;
log_bayesian_model = numeric(m)
for(i in 1:m){
log_bayesian_model[i] = log_bayesian(X, θ[i], λ)
}
plot(θ, log_bayesian_model, type="l", xlim=c(0,1), ylim=c(-500, 0), main="Bayesian model", xlab="θ", ylab="Log-Bayesian", col="green")
θstar_b = max_bayesian(X, λ)
# Task 5
# Compare new generated observations to original ones
new_observations = rexp(n=50, rate = θstar_n)
data.frame(X, new_observations)
new_observations = rexp(n=50, rate = θstar_n)
data.frame(X, new_observations)
new_observations = rexp(n=50, rate = θstar_n)
# returns the loglikelihood value for given θ and vector X
loglikelihood = function(x, θ){
return(length(x)*log(θ)-θ*sum(x))
}
# returns the max logilikelihood value for the given distribution estimation
max_loglikelihood = function(x){
return(length(x)/sum(x))
}
# returns log value of the bayesian proportional probability for given θ, λ and vector X
log_bayesian = function(x, θ, λ){
n = length(x)
#return(n*log(θ)-θ*sum(x)+n*log(λ)-n*λ*θ)
return(n*log(θ)-θ*sum(x)+log(λ)-λ*θ)
}
max_bayesian = function(x, λ){
n = length(x)
return (n/(sum(x)+n*λ))
}
###########################################################################
# Task 1
# Data preparation
dataframe = read.csv("machines.csv", dec=',')
X = dataframe[1]$Length # X vector
X_6 = X[1:6] # X vector of first 6 values
θ = seq(from=0, to=20, by=0.025) # θs to test
m = length(θ) # Amount of θs to be tested
loglikelihood_n = numeric(m) # Empty vector for loglikelihood values with all x values
loglikelihood_6 = numeric(m) # Empty vector for loglikelihood values the first 6 values
# Task 2
# Calculate the loglikelihoods for different θ values with the given vectors
for(i in 1:m){
loglikelihood_n[i] = loglikelihood(X, θ[i])
loglikelihood_6[i] = loglikelihood(X_6, θ[i])
}
# Task 3
# Plot the loglikelihoods
plot(θ, loglikelihood_6, type="l", main="Dependence of Log-Likelihood and θ (n values)", xlab="θ", ylab="Log-Likelihood", col="green")
lines(θ, loglikelihood_n, col="blue")
# θ values for maximum loglikelihoods
θstar_n = max_loglikelihood(X)
θstar_6 = max_loglikelihood(X_6)
# Task 4
# Plot the Bayesian Model
λ = 10;
log_bayesian_model = numeric(m)
for(i in 1:m){
log_bayesian_model[i] = log_bayesian(X, θ[i], λ)
}
plot(θ, log_bayesian_model, type="l", xlim=c(0,1), ylim=c(-500, 0), main="Bayesian model", xlab="θ", ylab="Log-Bayesian", col="green")
θstar_b = max_bayesian(X, λ)
# Task 5
# Compare new generated observations to original ones
new_observations = rexp(n=50, rate = θstar_n)
#data.frame(X, new_observations)
hist(new_observations, col="green", xlim=c(0,5), ylim=c(0,25), main="Original observations", xlab="x")
x11()
hist(X, col="blue", xlim=c(0,5), ylim=c(0,25), main="New observations", xlab="x")
plot(θ, log_bayesian_model, type="l", xlim=c(0,1), ylim=c(-500, 0), main="Bayesian model", xlab="θ", ylab="Log-Bayesian", col="green")
plot(θ, log_bayesian_model, type="l", xlim=c(0,20), ylim=c(-500, 0), main="Bayesian model", xlab="θ", ylab="Log-Bayesian", col="green")
θstar_b = max_bayesian(X, λ)
θstar_b
max_bayesian = function(x, λ){
n = length(x)
#return (n/(sum(x)+n*λ))
return (n/(sum(x)+λ))
}
θstar_b = max_bayesian(X, λ)
θstar_b
θstar_b = max_bayesian(X, λ)
θstar_b = max_bayesian(X, λ)
θstar_b
θstar_n
library(MASS)
# Task 1
dataframe = read.csv("tecator.csv", dec=',')
dataframe = dataframe[-215,]
protein = dataframe$Protein
moisture = dataframe$Moisture
fat = dataframe$Fat
channels = as.matrix(dataframe[1:100])
plot(protein, moisture)
# Task 2
# M1 = B0+B1*p+ε, where ε = N~(0, σ)
# M2 = B0+B1*p+B2*p²+ε, where ε=N~(0, σ)
# M3 = B0+B1*p+B2*p²+B3*p³+ε, where ε=N~(0, σ)
# etc.
# MSE criterion is appropriate to use since it minimizes the errors in our predicions (deviation of ε)
# Task 3
n = dim(dataframe)[1]
ids = sample(1:n, floor(n/2))
training = dataframe[ids,]
validation = dataframe[-ids,]
p = training$Protein
p2 = p^2
p3 = p^3
p4 = p^4
p5 = p^5
p6 = p^6
X1 = cbind(p)
X2 = cbind(p, p2)
X3 = cbind(p, p2, p3)
X4 = cbind(p, p2, p3, p4)
X5 = cbind(p, p2, p3, p4, p5)
X6 = cbind(p, p2, p3, p4, p5, p6)
#B = solve(t(X)%*%X)%*%t(X)%*%Y if I was to calculate it myself, did not work for higher polynomial terms of power
M1 = lm(Moisture ~ X1, data=training)
M2 = lm(Moisture ~ X2, data=training)
M3 = lm(Moisture ~ X3, data=training)
M4 = lm(Moisture ~ X4, data=training)
M5 = lm(Moisture ~ X5, data=training)
M6 = lm(Moisture ~ X6, data=training)
# Make the predictions
fitted_validation1 = predict(M1, validation)
fitted_validation2 = predict(M2, validation)
fitted_validation3 = predict(M3, validation)
fitted_validation4 = predict(M4, validation)
fitted_validation5 = predict(M5, validation)
fitted_validation6 = predict(M6, validation)
fitted_training1 = predict(M1)
fitted_training2 = predict(M2)
fitted_training3 = predict(M3)
fitted_training4 = predict(M4)
fitted_training5 = predict(M5)
fitted_training6 = predict(M6)
# Calculate the MSEs
# Validation MSEs
mse_v1 = mean((validation$Moisture-fitted_validation1)^2)
mse_v2 = mean((validation$Moisture-fitted_validation2)^2)
mse_v3 = mean((validation$Moisture-fitted_validation3)^2)
mse_v4 = mean((validation$Moisture-fitted_validation4)^2)
mse_v5 = mean((validation$Moisture-fitted_validation5)^2)
mse_v6 = mean((validation$Moisture-fitted_validation6)^2)
# Training MSEs
mse_t1 = mean((training$Moisture-fitted_training1)^2)
mse_t2 = mean((training$Moisture-fitted_training2)^2)
mse_t3 = mean((training$Moisture-fitted_training3)^2)
mse_t4 = mean((training$Moisture-fitted_training4)^2)
mse_t5 = mean((training$Moisture-fitted_training5)^2)
mse_t6 = mean((training$Moisture-fitted_training6)^2)
# Plot
mse_v = c(mse_v1, mse_v2, mse_v3, mse_v4, mse_v5, mse_v6)
mse_t = c(mse_t1, mse_t2, mse_t3, mse_t4, mse_t5, mse_t6)
plot(1:6, mse_v, type="l", col="green", ylim=c(0,180))
lines(1:6, mse_t, type="l", col="blue")
idx = !colnames(training) %in% c("Sample", "Fat", "Protein", "Moisture")
formulax = paste("Fat~", paste(colnames(training[,idx]), collapse = "+"))
#Task 4
fit = lm(formula(formulax), data=dataframe)
step = stepAIC(fit, direction="both")
step$anova
summary(step)
step = stepAIC(fit, direction="both", trace=FALSE)
